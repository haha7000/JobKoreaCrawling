"""ë©”ì¸ ì‹¤í–‰ íŒŒì¼"""
import json
from pathlib import Path
from src.config import JobKoreaConfig
from src.payload_manager import PayloadManager
from src.scraper import JobKoreaScraper
from src.excel_config_parser import ExcelConfigParser
from src.account_manager import AccountManager


def run_single_account(
    excel_path: str,
    sheet_name: str,
    start_page: int = 1,
    end_page: int = 1,
    page_size: int = 100,
    delay: float = 1.0,
    output_dir: str = "output",
    filter_active_within_minutes: int = None
) -> bool:
    """
    ë‹¨ì¼ ê³„ì •ìœ¼ë¡œ ê²€ìƒ‰ ì‹¤í–‰

    Args:
        excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        sheet_name: ì‹œíŠ¸ëª… (ê³„ì • ì•„ì´ë””)
        start_page: ì‹œì‘ í˜ì´ì§€
        end_page: ë í˜ì´ì§€
        page_size: í˜ì´ì§€ë‹¹ í¬ê¸°
        delay: ì§€ì—° ì‹œê°„(ì´ˆ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        filter_active_within_minutes: ìµœê·¼í™œë™ í•„í„°ë§ (ë¶„ ë‹¨ìœ„, Noneì´ë©´ í•„í„°ë§ ì•ˆ í•¨)

    Returns:
        ì„±ê³µ ì—¬ë¶€
    """
    # 1ï¸âƒ£ ê³„ì • ì •ë³´ ë¡œë“œ
    account_manager = AccountManager(excel_path)
    credentials = account_manager.get_credentials(sheet_name)

    if not credentials:
        print(f"âš ï¸  ê³„ì • '{sheet_name}'ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return False

    username = credentials['username']
    password = credentials['password']

    # 2ï¸âƒ£ ê²€ìƒ‰ ì¡°ê±´ ë¡œë“œ
    parser = ExcelConfigParser(excel_path, sheet_name)
    search_config = parser.parse()

    if not search_config:
        print("âš ï¸  ê²€ìƒ‰ ì„¤ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        return False

    # ê²€ìƒ‰ ì¡°ê±´ ì¶œë ¥
    _print_search_config(excel_path, sheet_name, username, search_config, start_page, end_page, page_size)

    # 3ï¸âƒ£ ìŠ¤í¬ë˜í¼ ì´ˆê¸°í™”
    config = JobKoreaConfig(username=username, password=password)
    payload_manager = PayloadManager("data/payload_template.json")
    scraper = JobKoreaScraper(
        config=config,
        payload_manager=payload_manager,
        output_dir=output_dir,
        filter_active_within_minutes=filter_active_within_minutes
    )

    # 4ï¸âƒ£ ë°ì´í„° ìˆ˜ì§‘
    people = scraper.scrape(
        start_page=start_page,
        end_page=end_page,
        page_size=page_size,
        delay=delay,
        job_name=search_config['job_names'],
        areas=search_config['areas'],
        education=search_config['education'],
        ages=search_config['ages'],
        genders=search_config['genders'],
        job_status=search_config['job_status']
    )

    # 5ï¸âƒ£ ê²°ê³¼ ì €ì¥
    _save_results(people, sheet_name, output_dir, scraper)

    return True


def run_all_accounts(
    excel_path: str = "configs/jobkorea_Excel.xlsx",
    start_page: int = 1,
    end_page: int = 2,
    page_size: int = 200,
    delay: float = 1.0,
    output_dir: str = "output",
    filter_active_within_minutes: int = None
):
    """
    ì—‘ì…€ íŒŒì¼ì˜ ëª¨ë“  ê³„ì •ì„ ìˆœì°¨ ì‹¤í–‰

    Args:
        excel_path: ì—‘ì…€ íŒŒì¼ ê²½ë¡œ
        start_page: ì‹œì‘ í˜ì´ì§€
        end_page: ë í˜ì´ì§€
        page_size: í˜ì´ì§€ë‹¹ í¬ê¸°
        delay: ì§€ì—° ì‹œê°„(ì´ˆ)
        output_dir: ì¶œë ¥ ë””ë ‰í† ë¦¬
        filter_active_within_minutes: ìµœê·¼í™œë™ í•„í„°ë§ (ë¶„ ë‹¨ìœ„, Noneì´ë©´ í•„í„°ë§ ì•ˆ í•¨)
    """
    # ì—‘ì…€ íŒŒì¼ í™•ì¸
    if not Path(excel_path).exists():
        print(f"âŒ ì—‘ì…€ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {excel_path}")
        return

    # ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„ì • ì‹œíŠ¸ ëª©ë¡ ê°€ì ¸ì˜¤ê¸°
    account_manager = AccountManager(excel_path)
    valid_sheets = account_manager.get_valid_account_sheets()

    if not valid_sheets:
        print("âŒ ì‹¤í–‰ ê°€ëŠ¥í•œ ê³„ì •ì´ ì—†ìŠµë‹ˆë‹¤.")
        print(f"   - ê³„ì • ì‹œíŠ¸ì— ë“±ë¡ëœ ì•„ì´ë””: {account_manager.list_accounts()}")
        print(f"   - ì—‘ì…€ì˜ ëª¨ë“  ì‹œíŠ¸: {account_manager.get_all_sheet_names()}")
        return

    # ì‹¤í–‰ ì •ë³´ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸš€ ë‹¤ì¤‘ ê³„ì • ì‹¤í–‰ ì‹œì‘")
    print(f"ğŸ“‹ ì—‘ì…€ íŒŒì¼: {excel_path}")
    print(f"ğŸ”¢ ì‹¤í–‰ ê³„ì • ìˆ˜: {len(valid_sheets)}ê°œ")
    print(f"ğŸ“„ ì‹¤í–‰ ê³„ì •: {', '.join(valid_sheets)}")
    print(f"{'='*60}\n")

    # ìˆœì°¨ ì‹¤í–‰
    success_count = 0
    fail_count = 0

    for idx, sheet_name in enumerate(valid_sheets, 1):
        print(f"\n{'='*60}")
        print(f"[{idx}/{len(valid_sheets)}] ğŸ“Œ ê³„ì •: {sheet_name}")
        print(f"{'='*60}\n")

        success = run_single_account(
            excel_path=excel_path,
            sheet_name=sheet_name,
            start_page=start_page,
            end_page=end_page,
            page_size=page_size,
            delay=delay,
            output_dir=output_dir,
            filter_active_within_minutes=filter_active_within_minutes
        )

        if success:
            success_count += 1
        else:
            fail_count += 1

        print(f"\n{'='*60}")
        print(f"âœ… [{idx}/{len(valid_sheets)}] {sheet_name} ì™„ë£Œ")
        print(f"{'='*60}\n")

    # ìµœì¢… ê²°ê³¼ ì¶œë ¥
    print(f"\n{'='*60}")
    print(f"ğŸ‰ ì „ì²´ ì‹¤í–‰ ì™„ë£Œ!")
    print(f"   âœ… ì„±ê³µ: {success_count}ê°œ")
    if fail_count > 0:
        print(f"   âŒ ì‹¤íŒ¨: {fail_count}ê°œ")
    print(f"{'='*60}\n")


def _print_search_config(excel_path: str, sheet_name: str, username: str, config: dict, start_page: int, end_page: int, page_size: int):
    """ê²€ìƒ‰ ì¡°ê±´ ì¶œë ¥"""
    print(f"ğŸ”‘ ê³„ì •: {username}")
    print(f"ğŸ“„ ê²€ìƒ‰ì¡°ê±´ ì‹œíŠ¸: {sheet_name}\n")

    print(f"ğŸ” ê²€ìƒ‰ ì¡°ê±´:")
    print(f"   ëŒ€ë¶„ë¥˜: {', '.join(config['categories'])}")
    print(f"   ì§ë¬´: {', '.join(config['job_names'][:5])}{'...' if len(config['job_names']) > 5 else ''} (ì´ {len(config['job_names'])}ê°œ)")
    print(f"   ì§€ì—­: {config['areas']}")
    print(f"   í•™ë ¥: {config['education']}")
    print(f"   ë‚˜ì´: {config['ages']}")
    print(f"   êµ¬ì§ìƒíƒœ: {config['job_status']}")
    print(f"   í˜ì´ì§€: {start_page} ~ {end_page} (í¬ê¸°: {page_size})\n")


def _save_results(people: list, sheet_name: str, output_dir: str, scraper):
    """ê²°ê³¼ ì €ì¥"""
    if people:
        # íŒŒì¼ëª…: ì‹œíŠ¸ëª… ê¸°ë°˜
        safe_sheet_name = sheet_name.replace('@', '_').replace('.', '_')
        json_path = Path(output_dir) / f"{safe_sheet_name}_summary.json"
        excel_path = Path(output_dir) / f"{safe_sheet_name}_ê²°ê³¼.xlsx"

        # JSON ì €ì¥
        with open(json_path, "w", encoding="utf-8") as f:
            json.dump(people, f, ensure_ascii=False, indent=2)

        # ì—‘ì…€ ì €ì¥
        scraper.exporter.save(people, str(excel_path))

        print(f"âœ… ì™„ë£Œ: {len(people)}ëª… ìˆ˜ì§‘")
        print(f"   ğŸ“„ JSON: {json_path}")
        print(f"   ğŸ“Š Excel: {excel_path}")
    else:
        print(f"âš ï¸  ìˆ˜ì§‘ëœ ë°ì´í„° ì—†ìŒ")


def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    # ==================== ğŸ”§ ì‹¤í–‰ ì„¤ì • ====================

    EXCEL_PATH = "configs/jobkorea_Excel.xlsx"  # ì—‘ì…€ íŒŒì¼ ê²½ë¡œ

    # í˜ì´ì§€ ì„¤ì •
    START_PAGE = 1
    END_PAGE = 2
    PAGE_SIZE = 100
    DELAY = 1.0

    OUTPUT_DIR = "output"

    # ğŸ”¥ ìµœê·¼í™œë™ í•„í„°ë§ ì„¤ì • (ë¶„ ë‹¨ìœ„)
    FILTER_ACTIVE_WITHIN_MINUTES = 30  # 30ë¶„ ì´ë‚´ í™œë™í•œ ì‚¬ìš©ìë§Œ ì¶”ì¶œ

    # =====================================================

    # ëª¨ë“  ê³„ì • ìë™ ì‹¤í–‰
    run_all_accounts(
        excel_path=EXCEL_PATH,
        start_page=START_PAGE,
        end_page=END_PAGE,
        page_size=PAGE_SIZE,
        delay=DELAY,
        output_dir=OUTPUT_DIR,
        filter_active_within_minutes=FILTER_ACTIVE_WITHIN_MINUTES
    )


if __name__ == "__main__":
    main()
